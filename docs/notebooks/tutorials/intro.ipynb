{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kulprit: Kullback-Leibler projections for Bayesian model selection in Python\n",
    "\n",
    "## Introduction to projection predictive model selection\n",
    "\n",
    "The Bayesian community has recently witnessed a rapid growth in theoretical and applied contributions to building and selecting predictive models. Projection predictive inference, based on the ideas of Goutis and Robert (1998) and Dupuis and Robert (2003), in particular has shown promise in doing so, finding application in medical statistics and deep learning. It is less prone to over-fitting than naïve selection based purely on cross-validated performance metrics, and has been known to out-perform the maximum _a posteriori_ model in terms of predictive performance.\n",
    "\n",
    "## Data\n",
    "\n",
    "For this tutorial we will use some simple simulated data following a Gaussian observation model. We simulate $n = 100$ samples from $p = 10$ covariates of which $5$ are informative using `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.680064</td>\n",
       "      <td>-0.984860</td>\n",
       "      <td>-0.366224</td>\n",
       "      <td>0.714086</td>\n",
       "      <td>1.061680</td>\n",
       "      <td>-1.646574</td>\n",
       "      <td>-0.781754</td>\n",
       "      <td>0.455838</td>\n",
       "      <td>-0.549827</td>\n",
       "      <td>-0.103266</td>\n",
       "      <td>-127.868553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.830827</td>\n",
       "      <td>-0.472179</td>\n",
       "      <td>-0.136099</td>\n",
       "      <td>0.846852</td>\n",
       "      <td>1.726024</td>\n",
       "      <td>0.553260</td>\n",
       "      <td>0.299936</td>\n",
       "      <td>-0.580556</td>\n",
       "      <td>1.175503</td>\n",
       "      <td>-0.751056</td>\n",
       "      <td>11.811356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.018780</td>\n",
       "      <td>0.313205</td>\n",
       "      <td>0.249717</td>\n",
       "      <td>-0.949877</td>\n",
       "      <td>0.927114</td>\n",
       "      <td>1.267923</td>\n",
       "      <td>0.694952</td>\n",
       "      <td>-0.499052</td>\n",
       "      <td>-0.375417</td>\n",
       "      <td>0.864203</td>\n",
       "      <td>84.008588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.037483</td>\n",
       "      <td>0.370091</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>0.010198</td>\n",
       "      <td>-0.047468</td>\n",
       "      <td>3.154536</td>\n",
       "      <td>-0.649931</td>\n",
       "      <td>0.014903</td>\n",
       "      <td>-0.154008</td>\n",
       "      <td>-0.142315</td>\n",
       "      <td>-48.928065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.764305</td>\n",
       "      <td>-0.312410</td>\n",
       "      <td>0.639188</td>\n",
       "      <td>-1.820319</td>\n",
       "      <td>0.243066</td>\n",
       "      <td>0.319869</td>\n",
       "      <td>-0.825935</td>\n",
       "      <td>-1.244126</td>\n",
       "      <td>-0.291510</td>\n",
       "      <td>-0.421003</td>\n",
       "      <td>-86.303455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0 -0.680064 -0.984860 -0.366224  0.714086  1.061680 -1.646574 -0.781754   \n",
       "1 -1.830827 -0.472179 -0.136099  0.846852  1.726024  0.553260  0.299936   \n",
       "2  3.018780  0.313205  0.249717 -0.949877  0.927114  1.267923  0.694952   \n",
       "3  0.037483  0.370091 -0.068332  0.010198 -0.047468  3.154536 -0.649931   \n",
       "4  0.764305 -0.312410  0.639188 -1.820319  0.243066  0.319869 -0.825935   \n",
       "\n",
       "         x7        x8        x9           y  \n",
       "0  0.455838 -0.549827 -0.103266 -127.868553  \n",
       "1 -0.580556  1.175503 -0.751056   11.811356  \n",
       "2 -0.499052 -0.375417  0.864203   84.008588  \n",
       "3  0.014903 -0.154008 -0.142315  -48.928065  \n",
       "4 -1.244126 -0.291510 -0.421003  -86.303455  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# generate the data\n",
    "n, p = 100, 10\n",
    "X, y = make_regression(n_samples=n, n_features=p, n_informative=5)\n",
    "data = np.append(X, y[:, None], axis=1)\n",
    "covnames = [f\"x{x}\" for x in range(p)]\n",
    "df = pd.DataFrame(data, columns=covnames + [\"y\"])\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference model\n",
    "\n",
    "First, we have to construct a reference model for the projection predictive variable selection. This model is considered as the best (“reference”) solution to the prediction task. The aim of the projection predictive variable selection is to find a subset of a set of candidate predictors which is as small as possible but achieves a predictive performance as close as possible to that of the reference model.\n",
    "\n",
    "The rich reference model is a model we consider to be good in terms of predictive performance, and one we would be happy using as-is. Model selection then becomes applicable when we\n",
    "1. have a predictive rich model, but would like to reduce computational burden,\n",
    "2. would like to use a model more robust to changes in the data-generating distribution, or\n",
    "3. would like to gain a better understanding of important correlation structures.\n",
    "\n",
    "`kulprit` requires the `arviz.InferenceData` object associated with a fitted `bambi` reference model, as well as the `bambi.Model` object. This `Model` will define the search space in the projection predictive model selection procedure, and the `InferenceData` provides the posterior predictive distribution to emulate. In general, the `InferenceData` need not come from the `Model` object. In other words, `kulprit` naturally allows for the reference model to be different from the search space, affording the statistician the possibility to fit a non-parametric reference model but search through an interpretable space. For the sake of this demonstration, we will only consider nested submodels of the reference model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 00:23&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 23 seconds.\n"
     ]
    }
   ],
   "source": [
    "import bambi as bmb\n",
    "import arviz as az\n",
    "\n",
    "# fit the reference model\n",
    "model = bmb.Model(f\"y ~ {' + '.join(covnames)}\", df)\n",
    "idata = model.fit(draws=1000, chains=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine these object into a `kulprit.ReferenceModel` object as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kulprit as kpt\n",
    "\n",
    "# intiate reference model\n",
    "ref_model = kpt.ReferenceModel(model, idata)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection\n",
    "\n",
    "Model selection in our case broadly consists of two components: the _search_ component and the _projection_ component.\n",
    "\n",
    "### Projection\n",
    "\n",
    "In essence, the \"projection\" stage of our model selection procued is achieved by fitting to the fit of the reference model. \n",
    "\n",
    "Denote $\\theta$ the parameters of the reference model, and $\\theta_\\perp$ those of some submodel. We are primarily interested in inferring submodel parameter values that optimise for prediction. In the original formulation by Goutis and Robert (1998), one looks to replace some reference model's posterior, denoted $p(\\theta\\mid \\mathcal{D})$ herein, with some restricted posterior $q(\\theta_\\perp)$ such that their induced posterior predictive distributions, $p(\\tilde{y} \\mid \\theta, \\mathcal{D})$ and $q(\\tilde{y}\\mid\\theta_\\perp)$, are as similar as possible. This similarity is quantified by Kullback-Leibler distance (KL; Kullback and Leibler, 1951). Formally, we aim to produce this restricted posterior $q(\\theta_\\perp)$ such that\n",
    "\n",
    "$$\n",
    "q(\\theta_\\perp) = {\\arg\\,\\min}_{q\\in\\mathscr{Q}(\\Theta)} \\mathbb{KL}\\{p(\\tilde{y}\\mid\\theta, \\mathcal{D}) \\mid q(\\tilde{y})\\}.\n",
    "$$\n",
    "\n",
    "### Search\n",
    "\n",
    "We currently account for two main methods of search: forward search, and Lasso-type search ($L_1$ search). We recommend that users favour forward search over $L_1$ search when searching up to $40$ covariates as it broadly produces \"better\" solution paths (by which we mean less selection-induced over-fitting).\n",
    "\n",
    "In forward search, we begin by projecting the reference model onto the \"empty\" (intercept-only) model, which acts as the root of our search tree. We then project the reference model onto all models with one predictor and the intercept term, and select the single-predictor model whose posterior predictive distribution is closest to the reference model's posterior predictive distribution (possibly coarsened by clustering or thinning the posterior draws) in KL divergence sense and as defined in Section~\\ref{sec:projpred}. Denote this first predictor to be selected $x^{(1)}$. Following this, we fit all size-two models including the intercept and $x^{(1)}$ (``size-two'' does not count the intercept here), and once more select the one closest to the reference model in terms of KL divergence of their posterior predictive distributions. Denote this second predictor to be selected $x^{(2)}$. This is repeated until either all predictors are selected, or some pre-defined limit on the model size is reached. Our solution path is then the list of predictors ordered by the stage at which they were selected: in our example $(\\text{Intercept}, x^{(1)},x^{(2)},\\dotsc)$. \n",
    "\n",
    "Tangentially, $L_1$ search can reduce computational cost by fitting a model with Lasso penalty to the in-sample predictions made by the reference model (thus, the $L_1$ search solves an $L_1$-penalised projection problem, whereas the forward search solves the original projection problem) and investigating the order in which the predictors enter the Lasso model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_model.search()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model size selection\n",
    "\n",
    "We now do not reason directly on the submodels, but rather their sizes. That is to say that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yannmclatchie/Desktop/kulprit/.venv/lib/python3.9/site-packages/arviz/stats/stats.py:803: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  warnings.warn(\n",
      "/Users/yannmclatchie/Desktop/kulprit/.venv/lib/python3.9/site-packages/arviz/stats/stats.py:803: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Encountered error in ELPD computation of compare.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/kulprit/.venv/lib/python3.9/site-packages/arviz/stats/stats.py:448\u001b[0m, in \u001b[0;36m_calculate_ics\u001b[0;34m(compare_dict, scale, ic, var_name)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 448\u001b[0m     compare_dict[name] \u001b[39m=\u001b[39m ic_func(\n\u001b[1;32m    449\u001b[0m         convert_to_inference_data(dataset),\n\u001b[1;32m    450\u001b[0m         pointwise\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    451\u001b[0m         scale\u001b[39m=\u001b[39;49mscale,\n\u001b[1;32m    452\u001b[0m         var_name\u001b[39m=\u001b[39;49mvar_name,\n\u001b[1;32m    453\u001b[0m     )\n\u001b[1;32m    454\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/kulprit/.venv/lib/python3.9/site-packages/arviz/stats/stats.py:766\u001b[0m, in \u001b[0;36mloo\u001b[0;34m(data, pointwise, var_name, reff, scale)\u001b[0m\n\u001b[1;32m    765\u001b[0m inference_data \u001b[39m=\u001b[39m convert_to_inference_data(data)\n\u001b[0;32m--> 766\u001b[0m log_likelihood \u001b[39m=\u001b[39m _get_log_likelihood(inference_data, var_name\u001b[39m=\u001b[39;49mvar_name)\n\u001b[1;32m    767\u001b[0m pointwise \u001b[39m=\u001b[39m rcParams[\u001b[39m\"\u001b[39m\u001b[39mstats.ic_pointwise\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m pointwise \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m pointwise\n",
      "File \u001b[0;32m~/Desktop/kulprit/.venv/lib/python3.9/site-packages/arviz/stats/stats_utils.py:425\u001b[0m, in \u001b[0;36mget_log_likelihood\u001b[0;34m(idata, var_name)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(idata, \u001b[39m\"\u001b[39m\u001b[39mlog_likelihood\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 425\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mlog likelihood not found in inference data object\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    426\u001b[0m \u001b[39mif\u001b[39;00m var_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: log likelihood not found in inference data object",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/kulprit/.venv/lib/python3.9/site-packages/arviz/stats/stats.py:177\u001b[0m, in \u001b[0;36mcompare\u001b[0;34m(compare_dict, ic, method, b_samples, alpha, seed, scale, var_name)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     (ics_dict, scale, ic) \u001b[39m=\u001b[39m _calculate_ics(compare_dict, scale\u001b[39m=\u001b[39;49mscale, ic\u001b[39m=\u001b[39;49mic, var_name\u001b[39m=\u001b[39;49mvar_name)\n\u001b[1;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/kulprit/.venv/lib/python3.9/site-packages/arviz/stats/stats.py:455\u001b[0m, in \u001b[0;36m_calculate_ics\u001b[0;34m(compare_dict, scale, ic, var_name)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 455\u001b[0m             \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m(\n\u001b[1;32m    456\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEncountered error trying to compute \u001b[39m\u001b[39m{\u001b[39;00mic\u001b[39m}\u001b[39;00m\u001b[39m from model \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    457\u001b[0m             ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[39mreturn\u001b[39;00m (compare_dict, scale, ic)\n",
      "\u001b[0;31mTypeError\u001b[0m: Encountered error trying to compute loo from model 10.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# compare submodels found in the search by LOO-CV ELPD\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m cmp, ax \u001b[39m=\u001b[39m ref_model\u001b[39m.\u001b[39;49mloo_compare(plot\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m);\n\u001b[1;32m      3\u001b[0m cmp\n",
      "File \u001b[0;32m~/Desktop/kulprit/src/kulprit/reference.py:157\u001b[0m, in \u001b[0;36mReferenceModel.loo_compare\u001b[0;34m(self, ic, plot, method, b_samples, alpha, seed, scale, var_name, plot_kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloo_compare\u001b[39m(\n\u001b[1;32m    144\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    145\u001b[0m     ic: Optional[Literal[\u001b[39m\"\u001b[39m\u001b[39mloo\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwaic\u001b[39m\u001b[39m\"\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m     \u001b[39m# perform pair-wise predictive performance comparison with LOO\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m     comparison, axes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msearcher\u001b[39m.\u001b[39;49mloo_compare(\n\u001b[1;32m    158\u001b[0m         ic\u001b[39m=\u001b[39;49mic,\n\u001b[1;32m    159\u001b[0m         plot\u001b[39m=\u001b[39;49mplot,\n\u001b[1;32m    160\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    161\u001b[0m         b_samples\u001b[39m=\u001b[39;49mb_samples,\n\u001b[1;32m    162\u001b[0m         alpha\u001b[39m=\u001b[39;49malpha,\n\u001b[1;32m    163\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    164\u001b[0m         scale\u001b[39m=\u001b[39;49mscale,\n\u001b[1;32m    165\u001b[0m         var_name\u001b[39m=\u001b[39;49mvar_name,\n\u001b[1;32m    166\u001b[0m         plot_kwargs\u001b[39m=\u001b[39;49mplot_kwargs,\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m     \u001b[39mreturn\u001b[39;00m comparison, axes\n",
      "File \u001b[0;32m~/Desktop/kulprit/src/kulprit/search/searcher.py:111\u001b[0m, in \u001b[0;36mSearcher.loo_compare\u001b[0;34m(self, ic, plot, method, b_samples, alpha, seed, scale, var_name, plot_kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39midatas\u001b[39m.\u001b[39mupdate(\n\u001b[1;32m    103\u001b[0m     {\n\u001b[1;32m    104\u001b[0m         \u001b[39mlen\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m     }\n\u001b[1;32m    108\u001b[0m )\n\u001b[1;32m    110\u001b[0m \u001b[39m# compare the submodels by some criterion\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m comparison \u001b[39m=\u001b[39m az\u001b[39m.\u001b[39;49mcompare(\n\u001b[1;32m    112\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49midatas,\n\u001b[1;32m    113\u001b[0m     ic\u001b[39m=\u001b[39;49mic,\n\u001b[1;32m    114\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    115\u001b[0m     b_samples\u001b[39m=\u001b[39;49mb_samples,\n\u001b[1;32m    116\u001b[0m     alpha\u001b[39m=\u001b[39;49malpha,\n\u001b[1;32m    117\u001b[0m     seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    118\u001b[0m     scale\u001b[39m=\u001b[39;49mscale,\n\u001b[1;32m    119\u001b[0m     var_name\u001b[39m=\u001b[39;49mvar_name,\n\u001b[1;32m    120\u001b[0m )\n\u001b[1;32m    122\u001b[0m \u001b[39m# plot the comparison if requested\u001b[39;00m\n\u001b[1;32m    123\u001b[0m axes \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/kulprit/.venv/lib/python3.9/site-packages/arviz/stats/stats.py:179\u001b[0m, in \u001b[0;36mcompare\u001b[0;34m(compare_dict, ic, method, b_samples, alpha, seed, scale, var_name)\u001b[0m\n\u001b[1;32m    177\u001b[0m     (ics_dict, scale, ic) \u001b[39m=\u001b[39m _calculate_ics(compare_dict, scale\u001b[39m=\u001b[39mscale, ic\u001b[39m=\u001b[39mic, var_name\u001b[39m=\u001b[39mvar_name)\n\u001b[1;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 179\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEncountered error in ELPD computation of compare.\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    180\u001b[0m names \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ics_dict\u001b[39m.\u001b[39mkeys())\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m ic \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mloo\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Encountered error in ELPD computation of compare."
     ]
    }
   ],
   "source": [
    "# compare submodels found in the search by LOO-CV ELPD\n",
    "cmp, ax = ref_model.loo_compare(plot=True);\n",
    "cmp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[^1]: $\\tilde{y}$ is random variable sampled from some distribution. We will later see expectations taken with respect to $\\tilde{y}$ under some sample distribution $p$, denoted $\\mathbb{E}_{\\tilde{y}\\sim p}[\\cdot]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b2b7df85e895e1c4316290f5aaf26982dcc1b162585921f2ab63d2757844866"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
